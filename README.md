# Python Optimization - NYC Taxi Dataset

> De 2h17 Ã  11 minutes : Comment optimiser vos scripts Python
> Newsletter DataGyver #9

## ğŸ¯ Objectif

Ce projet dÃ©montre 3 techniques d'optimisation Python mesurables et reproductibles :

1. **Profiling avec py-spy** - Identifier les goulots d'Ã©tranglement
2. **Lazy Loading avec DuckDB** - Charger uniquement ce qui est nÃ©cessaire
3. **Vectorisation** - Ã‰liminer les boucles Python lentes

## ğŸ“Š Dataset

NYC Yellow Taxi Trip Records (Janvier 2022)
- 2.4M trajets
- ~38 Mo au format Parquet
- Source : [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)

## ğŸš€ Installation

### PrÃ©requis
- Python 3.9+
- [uv](https://github.com/astral-sh/uv) (gestionnaire de packages ultra-rapide)

### Installation rapide avec uv (recommandÃ©)
```bash
# Installer uv si nÃ©cessaire
# Windows: pip install uv
# macOS/Linux: curl -LsSf https://astral.sh/uv/install.sh | sh

# CrÃ©er l'environnement virtuel
uv venv

# Activer l'environnement
# Windows PowerShell:
.venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate

# Installer les dÃ©pendances (rapide avec uv!)
uv pip install -r requirements.txt

# TÃ©lÃ©charger le dataset NYC Taxi (~38 Mo)
curl -L "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet" -o "data/yellow_taxi.parquet"
# Ou sur Windows avec PowerShell:
# Invoke-WebRequest -Uri "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-01.parquet" -OutFile "data/yellow_taxi.parquet"
```

### Installation avec pip (alternative)
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

## ğŸ“ Structure du projet
```
.
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils/                 # Utilitaires communs
â”‚   â”œâ”€â”€ 01_profiling.py        # DÃ©monstration py-spy
â”‚   â”œâ”€â”€ 02_loading.py          # Pandas vs DuckDB
â”‚   â”œâ”€â”€ 03_vectorization.py    # Boucles vs vectorisation
â”‚   â”œâ”€â”€ 04_parallelization.py  # Traitement parallÃ¨le
â”‚   â”œâ”€â”€ 05_caching.py          # LRU cache
â”‚   â””â”€â”€ 06_full_benchmark.py   # Benchmark complet
â”œâ”€â”€ benchmarks/
â”‚   â””â”€â”€ run_all_benchmarks.py  # ExÃ©cute tous les benchmarks
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ download_data.sh       # TÃ©lÃ©charge le dataset NYC Taxi
â”œâ”€â”€ data/                      # DonnÃ©es (gitignored)
â”œâ”€â”€ results/                   # RÃ©sultats des benchmarks
â””â”€â”€ docs/                      # Documentation
```

## ğŸ”¬ Utilisation

### ExÃ©cution rapide avec uv
```bash
# 1. Profiling - Identifier les goulots d'Ã©tranglement
uv run src/01_profiling.py

# 2. Benchmark Pandas vs DuckDB - Lazy loading
uv run src/02_loading.py

# 3. Vectorisation - Boucles vs opÃ©rations vectorisÃ©es
uv run src/03_vectorization.py

# 4. ParallÃ©lisation - Traitement multi-fichiers
uv run src/04_parallelization.py

# 5. Caching LRU - MÃ©moisation des rÃ©sultats
uv run src/05_caching.py

# 6. Benchmark complet - Tous les tests
uv run benchmarks/run_all_benchmarks.py
```

### Profiling avancÃ© avec py-spy (nÃ©cessite droits admin sur Windows)
```bash
# GÃ©nÃ©rer un flamegraph interactif
py-spy record -o results/profile.svg -- python src/01_profiling.py

# Ouvrir le flamegraph dans votre navigateur
start results/profile.svg  # Windows
open results/profile.svg   # macOS
xdg-open results/profile.svg  # Linux
```

**Note :** Sur Windows, py-spy nÃ©cessite des droits administrateur. Lancez PowerShell en tant qu'administrateur si vous obtenez une erreur de permissions.

## ğŸ“ˆ RÃ©sultats mesurÃ©s

RÃ©sultats obtenus sur Windows 11, Python 3.12, CPU Intel/AMD moderne :

| Technique | Gain mesurÃ© | Temps avant | Temps aprÃ¨s | Impact |
|-----------|-------------|-------------|-------------|--------|
| **DuckDB vs Pandas** | **8.6x plus rapide** | 4.4s | 0.5s | Chargement & agrÃ©gation |
| **Vectorisation** | **1,821x plus rapide** | 135s | 0.07s | Calculs sur colonnes |
| **Caching LRU** | **3,350x plus rapide** | 78s | 0.02s | Appels rÃ©pÃ©titifs |
| **Profiling py-spy** | Boucle = 99.7% du temps | - | - | Identification du goulot |

### âš ï¸ Note sur la parallÃ©lisation
La parallÃ©lisation n'est efficace que sur des **traitements lourds** (fichiers >10 Mo ou calculs intensifs). Sur de petits fichiers, l'overhead de crÃ©ation de processus peut annuler le gain. Toujours profiler avant de parallÃ©liser !

### ğŸ’¡ LeÃ§on clÃ©
**Le vrai goulot d'Ã©tranglement :** Les boucles `for` sur DataFrames reprÃ©sentent 99.7% du temps d'exÃ©cution dans le script non optimisÃ©. La vectorisation offre les gains les plus spectaculaires (1,821x).

## ğŸ§ª VÃ©rifier que tout fonctionne

Pour tester rapidement l'installation :

```bash
# Test rapide : Benchmark complet (environ 3-4 minutes)
uv run benchmarks/run_all_benchmarks.py

# VÃ©rifier un script spÃ©cifique
uv run src/02_loading.py
```

Si vous voyez des rÃ©sultats de performances s'afficher, tout fonctionne correctement ! ğŸ‰

## ğŸ“š DÃ©tails des scripts

- **`01_profiling.py`** : DÃ©montre l'utilisation de py-spy pour identifier oÃ¹ le code perd son temps (boucle for vs merge)
- **`02_loading.py`** : Compare Pandas et DuckDB pour le chargement et l'agrÃ©gation de donnÃ©es
- **`03_vectorization.py`** : Montre la diffÃ©rence massive entre boucles for et opÃ©rations vectorisÃ©es
- **`04_parallelization.py`** : DÃ©montre la parallÃ©lisation (avec avertissement sur les petits fichiers)
- **`05_caching.py`** : Illustre l'impact du caching LRU sur les appels rÃ©pÃ©titifs
- **`06_full_benchmark.py`** : Compare Pandas, Polars et DuckDB sur plusieurs opÃ©rations

## ğŸ“ Pour aller plus loin

**Newsletter & Formations :**
- [Newsletter DataGyver](https://datagy.substack.com/) - Techniques data chaque semaine
- Formation Streamlit Unleashed - Construire des apps data performantes
- SQL Mastery - Optimisation SQL et bases de donnÃ©es

**Ressources techniques :**
- [py-spy Documentation](https://github.com/benfred/py-spy)
- [DuckDB Performance Guide](https://duckdb.org/why_duckdb)
- [Polars User Guide](https://docs.pola.rs/)

## ğŸ¤ Contribuer

Vous avez optimisÃ© un script avec ces techniques ? Partagez vos rÃ©sultats !

1. Fork le repo
2. Ajoutez votre exemple dans un nouveau script
3. CrÃ©ez une Pull Request avec vos rÃ©sultats

Ou simplement ouvrez une issue pour partager votre histoire d'optimisation !

## ğŸ“ Licence

MIT - GaÃ«l Penessot

---

**ğŸ’¡ Ce projet est 100% transparent :** Tous les chiffres annoncÃ©s sont reproductibles. Clone le repo et vÃ©rifie par toi-mÃªme !
